<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />

    <title>Análisis de tweets geolocalizados en Chile</title>

    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.1.10/require.min.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>

    <link rel="stylesheet" href="hito1.css" />

    <!-- Loading mathjax macro -->
    <!-- Load mathjax -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS_HTML"></script>
    <!-- MathJax configuration -->
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
          tex2jax: {
              inlineMath: [ ['$','$'], ["\\(","\\)"] ],
              displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
              processEscapes: true,
              processEnvironments: true
          },
          // Center justify equations in code and markdown cells. Elsewhere
          // we use CSS to left justify single line equations in code cells.
          displayAlign: 'center',
          "HTML-CSS": {
              styles: {'.MathJax_Display': {"margin": 0}},
              linebreaks: { automatic: true }
          }
      });
    </script>
    <!-- End of mathjax configuration -->
  </head>

  <body>
    <!-- Barra de navegación -->
    <div class="topnav">
      <a href="index.html">Introducción</a>
      <a href="exploracion.html">Exploración de datos</a>
      <a href="preguntas.html">Preguntas y problemas</a>
      <a class="active" href="propuesta.html">Propuesta experimental</a>
      <a href="resultado.html">Resultado</a>
      <a href="contribucion.html">Contribución</a>
    </div>

    <div tabindex="-1" id="notebook" class="border-box-sizing">
      <div class="container" id="notebook-container">
        <!-- Titulo -->
        <div class="cell border-box-sizing text_cell rendered">
          <div class="prompt input_prompt"></div>
          <div class="inner_cell">
            <div class="text_cell_render border-box-sizing rendered_html">
              <h1 id="Titulo">
                Propuesta experimental<a class="anchor-link" href="#Titulo"
                  >&#182;</a
                >
              </h1>
              <p>
                Metodología experimental asociada para responder las preguntas
                propuestas.
              </p>
              <h4>Dado un nuevo tweet, ¿será posible predecir de que región del país se publicó? (Ya implementado)</h4>
              <p>Primero, tenemos que aclarar que
              en este trabajo se usaron t&eacute;cnicas de NLP para lograr tal objetivo.
              Principalmente se desarrollaron dos modelos, LogisticRegression y Naive Bayes.
              Adem&aacute;s se utilizaron diferentes t&eacute;nicas de preprocesamiento de texto
              antes de pasar los tweets a los modelos. En el preprocesamiento del texto se us&oacute;
              lematizaci&oacute;n que es obtener la ra&iacute;z de la palabra, 
              otra t&eacute;nica para obtener tal prop&oacute;sito fue la de stemming, que es un algoritmo que 
              se aplica para obterner el mismo resultado descriot anteriormente.  Se eliminaron las stops words
              que son palabras que no aportan contenido al texto(conjunciones, preposiciones, art&iacute;culos).
              Hay que destacar tambi&eacute;n que se usaron n-gramas para la representaci&oacute;n del texto, 
              que no son m&aacute;s que secuencias de texto de longitud <i>n</i>.
              
              </p>
              <p>
                Entre las t&eacute;nicas de preprocesamiento y extracci&oacute;n de caracter&iacute;sticas 
                que se usaron fueron:
                <ul>
                    <li>Naive Bayes con Bag of words(BoW) sin tokenizaci&oacute;n -- Acc: 0.58</li>
                    <li>Naive bayes, BoW con tokenizador -- Acc: 0.58</li>
                    <li>Naive Bayes, con BoW con tokenizador sin stop words: -- Acc: 0.58</li>
                    <li>Naive Bayes, con BoW con tokenizador y lematizaci&oacute;n -- Acc: 0.57</li>
                    <li>Naive Bayes, con BoW con tokenizador y stemming -- Acc: 0.57</li>
                    <li>Naive Bayes, con n-gramas de longitud 5(mejor resultado) -- Acc: 0.59</li>
                    <li>Logistic LogisticRegression , BoW con stop wordS -- Acc: 0.59</li>
                </ul>
             </p>
             <p>
                Entre las conclusiones que pudimos sacar de estos experimentos est&aacute;n:
                <ul>
                    <li>Efectivamente se puede entrenar un clasificador que prediga la localidad desde donde se emiti&oacute;
                        un tweet dado las caracter&iacute;cas del texto.
                    </li>
                    <li>
                        Los resultados de todos los experimentos con las diferentes combinaciones de par&aacute;metros usados dan                          resultados muy similares y esto puede deberse principalmente a que el estilo usado de escritura en 
                        los tweets no hayan sido el correcto(mal escritos).
                    </li>
                    <li>
                       Otra pregunta de investigaci&oacute;n planteada en este trabajo fue que la temporalidad de los tweets no 
                       era un factor a tener en cuenta para clasificar por zonas.
                        Tenemos que decir que para la clasificaci&oacute;n de los tweets, cuando se us&oacute; el dataset completo                        los resultados bajaron mucho hasta un Acc: 40%. Y cuando se usaron tweets de un a&ntilde;o en 
                        espec&iacute;fico(2013 y 2017) el clasificador daba resultados mucho mejores como los reportados anteriormente.
                    </li>

                </ul>
             </p>
              
             En este trabajo tanto para el preprocesamiento de texto como para el entrenamiento de los modelos nos inspiramos en el siguiente colab <legend><b>https://colab.research.google.com/drive/1N_kK_S8LxfS0zdQ9MYNfaZCHegdfpMOX?usp=sharing</b></legend>
             <h4>¿Qué características del texto son determinantes al saber la zona geográfica de procedencia?</h4>
             <p>Para este punto se propone extraer distintos features desde el texto y usarlos para entrenar el clasificador.
              Estos serán los emoticones, largo del texto y principalmente los Hashtag.
              Se cree que estos Hashtags se refieren principalmente a entidades y por lo tanto su información sea más representativa de la zona que otro tipo de palabras.</p>
             
             <h4>¿Existe algún comportamiento asociado entre el momento de creación y la zona de donde procede?</h4>
             <p>Para esto habría que extraer como feature el horario de creación y entregarlo como input al clasificador.</p>
             
             <h4>¿Los criterios usados para clasificar los twitts son atemporales?</h4>
             <p>Para esto se propone dividir el dataset total en varios datasets.
              Se entrena un clasificador por año (con datos de ese mismo año) y se probará su desempeño en datos de otros años.
              Además se creará un clasificador que sea entrenado con datos de todos los años.
              Si los criterios fueran atemporales no debiese existir tanta diferencia en el desempeño entre los clasificador frente a un mismo conjunto de datos, sin importar su año de origen.</p>
             
             <h4>¿Existen tópicos más frecuentes en una zona que en otra?</h4>
             <p>En esta iteración del proyecto se efectuó un análisis sobre la distribución de los Hashtags, ya que se considera una buena aproximación al tópico que está siendo tocado en el tweet.
              Para la siguiente iteración se propone correr un reconocedor de entidades sobre los textos, esto significa un trabajo extra en cuanto al manejo de herramientas poderosas de NLP.
              Se espera que dado las diferentes ciudades, climas y culturas en chile, los tópicos hablados en cada región debieran ser diferentes.
              </p>
             
             <h4>¿Existen palabras o modismos que se repliquen entre twitts de una misma zona geográfica?</h4>
             <p>La idea tras esta pregunta es parecida a la de la pregunta anterior.
              Se propone investigar a fondo la distribución de las palabras en cada región.
              Luego eliminar las palabras comunes entre las diferentes clases, para finalmente presentarlas en un formato visual que sea claro y concluyente.</p>
             
             <br />
            <br />
             En este trabajo tanto para el preprocesamiento de texto como para el entrenamiento de los modelos nos inspiramos en el siguiente colab <legend><b>https://colab.research.google.com/drive/1N_kK_S8LxfS0zdQ9MYNfaZCHegdfpMOX?usp=sharing</b></legend>
            </div>
            
          </div>
        </div>

        <!-- FIN -->
      </div>
    </div>
    <footer>
      <span>Introducción a la Minería de Datos (CC5206) - Otoño 2021</span>
    </footer>
  </body>
</html>
